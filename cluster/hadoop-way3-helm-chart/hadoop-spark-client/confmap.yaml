apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-hadoop-conf-map
data:
  core-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
            <name>fs.defaultFS</name>
            <value>jfs://myjfs</value>
            <description>NameNode URI</description>
        </property>
      <property>
             <name>fs.jfs.impl</name>
             <value>io.juicefs.JuiceFileSystem</value>
         </property>
         <property>
             <name>fs.AbstractFileSystem.jfs.impl</name>
             <value>io.juicefs.JuiceFS</value>
         </property>
         <property>
             <name>juicefs.meta</name>
             <value>mysql://root:bigdata@(10.81.17.8:33066)/juicefs_k8s</value>
         </property>
         <property>
             <name>juicefs.cache-size</name>
             <value>1024</value>
         </property>
         <property>
             <name>juicefs.access-log</name>
             <value>/tmp/juicefs.access.log</value>
         </property>
         <property>
             <name>juicefs.cache-dir</name>
             <value>/tmp/data/juicefs</value>
         </property>
    </configuration>


  hive-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>hive.metastore.uris</name>
            <value>thrift://hive-metastore-service:9083</value>
        </property>
            <property>
               <name>hive.metastore.warehouse.dir</name>
               <value>/app/hive/warehouse</value>
           </property>
        <property>
            <name>hive.metastore.client.connect.retry.delay</name>
            <value>5</value>
        </property>
        
        <property>
            <name>hive.metastore.client.socket.timeout</name>
            <value>1800</value>
        </property>
           
        <property>
            <name>hive.server2.enable.doAs</name>
            <value>false</value>
        </property>
        
        <property>
            <name>hive.server2.thrift.port</name>
            <value>10018</value>
        </property>
        
        <property>
            <name>hive.server2.transport.mode</name>
            <value>binary</value>
        </property>

    </configuration>
      

  yarn-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

    <configuration>
      <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>bigdata-hadoop-yarn-rm</value>
      </property>

      <!-- Bind to all interfaces -->
      <property>
        <name>yarn.resourcemanager.bind-host</name>
        <value>0.0.0.0</value>
      </property>
      <property>
        <name>yarn.nodemanager.bind-host</name>
        <value>0.0.0.0</value>
      </property>
      <property>
        <name>yarn.timeline-service.bind-host</name>
        <value>0.0.0.0</value>
      </property>
      <!-- /Bind to all interfaces -->

      <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
      </property>

      <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
      </property>

      <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
      </property>

      <property>
        <description>List of directories to store localized files in.</description>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
      </property>

      <property>
        <description>Where to store container logs.</description>
        <name>yarn.nodemanager.log-dirs</name>
        <value>/var/log/hadoop-yarn/containers</value>
      </property>

      <property>
        <description>Where to aggregate logs to.</description>
        <name>yarn.nodemanager.remote-app-log-dir</name>
        <value>/var/log/hadoop-yarn/apps</value>
      </property>

      <property>
        <name>yarn.application.classpath</name>
        <value>
          /usr/local/hadoop/etc/hadoop,
          /usr/local/hadoop/share/hadoop/common/*,
          /usr/local/hadoop/share/hadoop/common/lib/*,
          /usr/local/hadoop/share/hadoop/hdfs/*,
          /usr/local/hadoop/share/hadoop/hdfs/lib/*,
          /usr/local/hadoop/share/hadoop/mapreduce/*,
          /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
          /usr/local/hadoop/share/hadoop/yarn/*,
          /usr/local/hadoop/share/hadoop/yarn/lib/*
        </value>
      </property>
    </configuration>


  mapred-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

    <configuration>
    	<property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        <property>
              <name>mapreduce.map.memory.mb</name>
              <value>5120</value>
        </property>
        <property>
              <name>mapreduce.reduce.memory.mb</name>
              <value>5120</value>
        </property>
    </configuration>



---
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-conf-map
data:
  spark-defaults.conf: |
    # spark.master                     spark://master:7077
    # spark.eventLog.enabled           true
    # spark.eventLog.dir               hdfs://namenode:8021/directory
    # spark.serializer                 org.apache.spark.serializer.KryoSerializer
    # spark.driver.memory              5g
    # spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
    spark.sql.catalog.spark_catalog    org.apache.iceberg.spark.SparkSessionCatalog
    spark.sql.extensions org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
    spark.history.ui.port 18080
    spark.history.retainedApplications 300
    spark.history.fs.logDirectory jfs://myjfs/spark3/history
    spark.eventLog.enabled           true
    spark.eventLog.dir               jfs://myjfs/spark3/history
    spark.yarn.historyServer.address=spark-history-svc:18080

